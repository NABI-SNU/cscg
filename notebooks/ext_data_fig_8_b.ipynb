{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cscg import CHMM, forwardE, backwardE, updateCE\n",
    "import matplotlib.pyplot as plt\n",
    "import igraph\n",
    "from matplotlib import cm, colors\n",
    "import os\n",
    "import seaborn as sb\n",
    "import scipy\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mess_fwd(chmm, x, pseudocount=0.0, pseudocount_E=0.0):\n",
    "    n_clones = chmm.n_clones\n",
    "    E = np.zeros((n_clones.sum(), len(n_clones)))\n",
    "    last = 0\n",
    "    for c in range(len(n_clones)):\n",
    "        E[last : last + n_clones[c], c] = 1\n",
    "        last += n_clones[c]\n",
    "    E += pseudocount_E\n",
    "    norm = E.sum(1, keepdims=True)\n",
    "    norm[norm == 0] = 1\n",
    "    E /= norm\n",
    "    T = chmm.C + pseudocount\n",
    "    norm = T.sum(2, keepdims=True)\n",
    "    norm[norm == 0] = 1\n",
    "    T /= norm\n",
    "    T = T.mean(0, keepdims=True)\n",
    "    log2_lik, mess_fwd = forwardE(\n",
    "        T.transpose(0, 2, 1), E, chmm.Pi_x, chmm.n_clones, x, x * 0, store_messages=True\n",
    "    )\n",
    "    return mess_fwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 10\n",
    "trial1x_let = np.repeat(np.array(['A','A','A','A','A','A','B', 'B', 'B', 'B', 'A','A','A', 'D','F','A','A','A','E','E', 'A', 'A', 'G','H','H','H']),1)\n",
    "trial2x_let = np.repeat(np.array(['A','A','A','A','A','A','C', 'C', 'C', 'C', 'A','A','A', 'D','D','A','A','A','E','F', 'A', 'A','G','H','H','H']),1)\n",
    "all_corr_runs = []\n",
    "\n",
    "for tot_rep in range(0,20):\n",
    "    np.random.seed(tot_rep)\n",
    "\n",
    "    print(tot_rep)\n",
    "\n",
    "    ln = np.random.choice(8, size=8, replace=False)\n",
    "    letter_num_dict = {'A': ln[0], 'B': ln[1], 'C': ln[2], 'D': ln[3], 'E': ln[4], 'F': ln[5], 'G': ln[6], 'H':ln[7]}\n",
    "\n",
    "    trial1x = np.zeros(len(trial1x_let))\n",
    "    trial2x = np.zeros(len(trial2x_let))\n",
    "    for i in range(len(trial1x_let)):\n",
    "        trial1x[i]= int(letter_num_dict.get(trial1x_let[i]))\n",
    "        trial2x[i] = int(letter_num_dict.get(trial2x_let[i]))\n",
    "    sb.heatmap([trial1x, trial2x])\n",
    "    plt.show()\n",
    "\n",
    "    trials = np.random.choice(2,num_trials-2)\n",
    "    trials = np.concatenate((trials, np.array([0,1])))\n",
    "\n",
    "    tr_len = len(trial1x)\n",
    "    x = np.zeros(num_trials*tr_len, dtype = np.int64)\n",
    "\n",
    "\n",
    "    for trial in range(len(trials)):\n",
    "        if trials[trial] == 0:\n",
    "            x[trial*tr_len: (trial+1)*tr_len] = trial1x\n",
    "        else:\n",
    "            x[trial*tr_len: (trial+1)*tr_len] = trial2x\n",
    "    a = np.zeros(len(x), dtype=np.int64)\n",
    "    OBS = len(np.unique(x))\n",
    "\n",
    "\n",
    "\n",
    "    n_clones = (np.ones(OBS + 5, dtype=np.int64) * 150)\n",
    "    chmm = CHMM(n_clones=n_clones, pseudocount=1e-10, x=x, a=a, seed = random.randint(1, 1000))  # Initialize the model\n",
    "    for tot_iter in range(0,50):\n",
    "\n",
    "        n_iter =10\n",
    "        progression = chmm.learn_em_T(x, a, n_iter=n_iter, term_early=False)  # Training\n",
    "        mess_fwd = get_mess_fwd(chmm, x, pseudocount_E=0.1)\n",
    "        corrplot = np.zeros((len(trials), len(trials)))\n",
    "        for trial1 in range(0, len(trials)):\n",
    "            for trial2 in range(trial1, len(trials)):\n",
    "                comp1 = mess_fwd[trial1*tr_len: (trial1+1)*tr_len,:]\n",
    "                comp2 = mess_fwd[trial2*tr_len: (trial2+1)*tr_len,:]\n",
    "                corrplot[trial1, trial2] = scipy.stats.pearsonr(comp1.flatten(), comp2.flatten())[0]\n",
    "\n",
    "        ## Correlation between near and far trial types\n",
    "        trial1 = mess_fwd[-tr_len:,:]\n",
    "        trial0 =  mess_fwd[-2*tr_len:-tr_len,:]\n",
    "        corr_plot1 = np.zeros((tr_len, tr_len))\n",
    "        corr_plot0 = np.zeros((tr_len, tr_len))\n",
    "        corr_plot01 = np.zeros((tr_len, tr_len))\n",
    "        for posi in range(0, tr_len):\n",
    "            for posj in range(0, tr_len):\n",
    "                corr_plot1[posi, posj] = scipy.stats.pearsonr(trial1[posi], trial1[posj])[0]\n",
    "                corr_plot0[posi, posj] = scipy.stats.pearsonr(trial0[posi], trial0[posj])[0]\n",
    "                corr_plot01[posi, posj] = scipy.stats.pearsonr(trial0[posi], trial1[posj])[0]\n",
    "        if tot_iter == 0:\n",
    "            all_corr = corr_plot01.copy()\n",
    "        else:\n",
    "            all_corr = np.dstack((all_corr,corr_plot01))\n",
    "\n",
    "    all_corr_runs.append(all_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trajectory of decorrelation during learningfor a particular simulation\n",
    "sim_chosen = 5\n",
    "all_corr = all_corr_runs[sim_chosen]\n",
    "sb.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "fig, axs = plt.subplots(1,5, figsize = (22,4))\n",
    "##fig, axs = plt.subplots(1,5, figsize = (12,2))\n",
    "counter = 0\n",
    "for stage in [0,2,5,20,30]:\n",
    "    corrplot01 = all_corr[:,:,stage][0:23,0:23]\n",
    "    sb.heatmap(corrplot01, ax= axs[counter], cmap = 'icefire', vmin= -1, vmax = 1, cbar= False,rasterized=True)\n",
    "    for lines in [6,10,13,15,18,20,23]:\n",
    "        axs[counter ].axvline(lines, linestyle=(0, (2, 5)), color='white', linewidth=1.5)\n",
    "        axs[counter ].axhline(lines, linestyle=(0, (2, 5)), color='white', linewidth=1.5)\n",
    "    ##axs[counter].set_yticks(np.arange(0,23,4), np.arange(0,230,40), rotation = 45)\n",
    "    ##axs[counter].set_xticks(np.arange(0,23,4), np.arange(0,230,40),rotation = 45)\n",
    "    axs[counter ].axhline(y=0, color='k',linewidth=5)\n",
    "    axs[counter].axhline(y=corrplot01.shape[1], color='k',linewidth=5)\n",
    "    axs[counter ].axvline(x=0, color='k',linewidth=5)\n",
    "    axs[counter ].axvline(x=corrplot01.shape[0], color='k',linewidth=5)\n",
    "    ##axs[counter].set_title('time ' + str(avging))\n",
    "    for (low, high) in [(6, 10), (13, 15), (18, 20)]:\n",
    "        axs[counter].plot([low, high, high, low, low], [low, low, high, high, low], color='white',linewidth=3)\n",
    "    axs[counter].set_aspect('equal')\n",
    "    axs[counter].axis('off')\n",
    "    ##axs[fig_count].set_title(stage*n_iter)\n",
    "    axs[counter].grid(False)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyze decorrelation of specific regions of interest across multiple simulations\n",
    "\n",
    "# Define 6 regions of interest\n",
    "tr_len = 26\n",
    "regions = [[0, 6], [10, 13], [15, 18], [20, 23]]\n",
    "\n",
    "other_regions = np.array([10,13,14,15,18,19,20,23])\n",
    "# Custom colors\n",
    "colors = ['white', 'gray', 'dodgerblue','navy','red','orange','cyan']\n",
    "\n",
    "correlation_matrix_1 = np.zeros((tr_len,tr_len))\n",
    "for i, region_i in enumerate(regions):\n",
    "    for j, region_j in enumerate(regions):\n",
    "        if i !=j:\n",
    "            for k in range(region_i[0], region_i[1]):\n",
    "                for l in range(region_j[0], region_j[1]):\n",
    "                    correlation_matrix_1[k, l] = 1\n",
    "\n",
    "\n",
    "correlation_matrix_2 = np.zeros_like(correlation_matrix_1)\n",
    "for i in range(other_regions[3], other_regions[5]):\n",
    "    for j in range(other_regions[3], other_regions[5]):\n",
    "        if i == j:\n",
    "            correlation_matrix_2[i, j] = 1\n",
    "\n",
    "\n",
    "correlation_matrix_3 = np.zeros_like(correlation_matrix_1)\n",
    "for i in range(other_regions[0], other_regions[2]):\n",
    "    for j in range(other_regions[0], other_regions[2]):\n",
    "        if i == j:\n",
    "            correlation_matrix_3[i, j] = 1\n",
    "\n",
    "\n",
    "correlation_matrix_4 = np.zeros_like(correlation_matrix_1)\n",
    "for i in range(0,6):\n",
    "    for j in range(0,6):\n",
    "        if i == j:\n",
    "            correlation_matrix_4[i, j] = 1\n",
    "\n",
    "correlation_matrix_5 = np.zeros_like(correlation_matrix_1)\n",
    "for i in range(6,10):\n",
    "    for j in range(6,10):\n",
    "        if i == j:\n",
    "            correlation_matrix_5[i, j] = 1\n",
    "\n",
    "\n",
    "correlation_matrix_6 = np.zeros_like(correlation_matrix_1)\n",
    "for i in range(20,23):\n",
    "    for j in range(20,23):\n",
    "        if i == j:\n",
    "            correlation_matrix_6[i, j] = 1\n",
    "\n",
    "correlation_matrices_1 = [correlation_matrix_1,correlation_matrix_2,correlation_matrix_3,correlation_matrix_4,correlation_matrix_5,correlation_matrix_6]\n",
    "colors = ['white', 'gray', 'dodgerblue','navy','red','orange','cyan']\n",
    "all_correlation_matrix = np.zeros_like(correlation_matrix_1)\n",
    "for i in range(len(correlation_matrices_1)):\n",
    "    all_correlation_matrix[correlation_matrices_1[i]== 1] = i+1\n",
    "custom_cmap = ListedColormap(colors)\n",
    "plt.imshow(all_correlation_matrix[0:23,0:23], cmap = custom_cmap, rasterized = True)\n",
    "for i, region in enumerate(regions):\n",
    "    plt.axvline(x=region[0]-0.5, color='black', linewidth=1, linestyle='--')\n",
    "    plt.axvline(x=region[1]-0.5, color='black', linewidth=1, linestyle='--')\n",
    "    plt.axhline(y=region[0]-0.5, color='black', linewidth=1, linestyle='--')\n",
    "    plt.axhline(y=region[1]-0.5, color='black', linewidth=1, linestyle='--')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrices_1 = [correlation_matrix_1,correlation_matrix_2,correlation_matrix_3,correlation_matrix_4,correlation_matrix_5,correlation_matrix_6]\n",
    "\n",
    "labels_1 = ['Off diagonal','Pre-R2', 'Pre-R1', 'Initial region','Indicator','End region']\n",
    "\n",
    "colors_1 = colors[1:7]\n",
    "all_masks_matrix = np.full((9,20,50), np.nan)\n",
    "\n",
    "countx = 0\n",
    "count = 0\n",
    "\n",
    "for session_n in range(20):\n",
    "    if count>3:\n",
    "        countx = countx + 1\n",
    "        count = 0\n",
    "\n",
    "    corr_position_day = all_corr_runs[session_n]\n",
    "\n",
    "    for i, mask in enumerate(correlation_matrices_1):\n",
    "        mask_array = np.zeros((corr_position_day.shape[2], corr_position_day.shape[0], corr_position_day.shape[1]), dtype=bool)\n",
    "        mask_array += mask.astype(bool)\n",
    "        masked_a_array = np.ma.masked_array(corr_position_day.T, mask=~mask_array)\n",
    "        mean_values_array = masked_a_array.mean(axis=(1, 2))\n",
    "\n",
    "        all_masks_matrix[i,session_n,0:len(mean_values_array)] = mean_values_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_time = []\n",
    "for rep in range(0, 20):\n",
    "    crossed1 = np.where(all_masks_matrix[1,rep,:]<0.1)[0]\n",
    "    crossed2 = np.where(all_masks_matrix[2,rep,:]<0.1)[0]\n",
    "    if len(crossed1)>0 and len(crossed2)>0:\n",
    "        end_time = np.maximum(crossed1[0], crossed2[0])+2\n",
    "        interp_mul = []\n",
    "        for loc in range(0,6):\n",
    "            mask_norm = all_masks_matrix[loc,rep,0:end_time].T\n",
    "            interp = np.interp(np.arange(0,50,1),  np.linspace(0,50,end_time),mask_norm)\n",
    "            interp_mul.append(interp)\n",
    "\n",
    "        if len(norm_time) == 0:\n",
    "            interp_all = np.array(interp_mul)\n",
    "        else:\n",
    "            interp_all = np.dstack((interp_all, np.array(interp_mul)))\n",
    "\n",
    "        norm_time.append(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks_matrix_new = all_masks_matrix[:,0:,:]\n",
    "crossed_postr1 = (all_masks_matrix_new[1][:,-1])<0.1\n",
    "crossed_prer1 = (all_masks_matrix_new[2][:,-1])<0.1\n",
    "plot_reps = crossed_postr1*crossed_prer1\n",
    "# Set square aspect ratio for both plots\n",
    "fig1, axs1 = plt.subplots(nrows=2, ncols=4, figsize=(13, 6), dpi=500)\n",
    "figx = 0\n",
    "figy = 0\n",
    "# Plot the first set of correlation matrices\n",
    "for i, mask in enumerate(correlation_matrices_1):\n",
    "    if figy>2:\n",
    "        figx = figx+1\n",
    "        figy = 0\n",
    "    axs1[figx,figy].plot(np.arange(0, 50*n_iter, n_iter),all_masks_matrix_new[i,plot_reps,:].T, 'o-', label=labels_1[i], color=colors_1[i], alpha = 0.3)\n",
    "\n",
    "    # Set the y-axis limits to 0 to 0.8 for the first plot\n",
    "    axs1[figx,figy].set_ylim([-0.2, 1.2])\n",
    "\n",
    "    # Add legend and labels for the first plot\n",
    "    #ax1.legend(fontsize='x-small')\n",
    "    ##axs1[figx,figy].set_xlabel('Session #')\n",
    "    ##axs1[figx,figy].set_ylabel('Correlation Coefficient')\n",
    "    if figx==0:\n",
    "        axs1[figx, figy].set_xticklabels([])\n",
    "    else:\n",
    "        axs1[figx, figy].set_xlabel('# iterations')\n",
    "    if figy>0:\n",
    "        axs1[figx, figy].set_yticklabels([])\n",
    "\n",
    "    axs1[figx,figy].spines['top'].set_visible(False)\n",
    "    axs1[figx,figy].spines['right'].set_visible(False)\n",
    "    axs1[figx,figy].set_title(labels_1[i])\n",
    "    figy = figy + 1\n",
    "\n",
    "for i in range(0,3):\n",
    "    means_plot = np.mean(interp_all[i], axis = 1)\n",
    "    std_plot = np.std(interp_all[i], axis = 1)\n",
    "    axs1[0,3].plot(np.linspace(0,1,50), means_plot, color=colors_1[i])\n",
    "    axs1[0,3].fill_between(np.linspace(0,1,50),means_plot-std_plot, means_plot+std_plot ,alpha=0.3, color=colors_1[i])\n",
    "axs1[0,3].set_ylim([-0.2, 1.2])\n",
    "axs1[0,3].spines['top'].set_visible(False)\n",
    "axs1[0,3].spines['right'].set_visible(False)\n",
    "axs1[0,3].set_title('Averaged')\n",
    "    ##axs1[0,3].set_xticklabels([])\n",
    "\n",
    "axs1[0,3].set_yticklabels([])\n",
    "\n",
    "rep_chosen = 0\n",
    "for i in range(0,3):\n",
    "    axs1[1,3].plot(np.linspace(0,1,50),interp_all[i, :,rep_chosen], 'o-', label=labels_1[i], color=colors_1[i])\n",
    "axs1[1,3].set_ylim([-0.2, 1.2])\n",
    "axs1[1,3].set_yticklabels([])\n",
    "axs1[1,3].set_xlabel('normalized time')\n",
    "axs1[1,3].spines['top'].set_visible(False)\n",
    "axs1[1,3].spines['right'].set_visible(False)\n",
    "axs1[1,3].set_title('Example simulation')\n",
    "##plt.tight_layout()\n",
    "\n",
    "# Set square aspect ratio for both plots\n",
    "##plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_session = np.array(all_corr_runs)[:,:,:,-1]\n",
    "\n",
    "# Calculate the mean for each 26x26 matrix\n",
    "averages = np.mean(last_session, axis=(1, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## threhold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_all_reshaped = np.transpose(interp_all, axes=(0, 2, 1))\n",
    "\n",
    "threshold = 0.3\n",
    "crossing_times = np.zeros((3, interp_all_reshaped.shape[1]))  # Initialize array to store crossing times\n",
    "crossing_percentages = np.zeros(3)  # Initialize array to store crossing percentages\n",
    "\n",
    "for zone in range(3):\n",
    "    for anm_n in range(interp_all_reshaped.shape[1]):\n",
    "        animal_data = interp_all_reshaped[zone, anm_n, :]\n",
    "\n",
    "        if np.any(animal_data <= threshold):\n",
    "            crossing_index = np.argmax(animal_data <= threshold)\n",
    "            crossing_times[zone, anm_n] = crossing_index / (interp_all_reshaped.shape[2] - 1)  # Normalize crossing time\n",
    "            crossing_percentages[zone] += 1\n",
    "        else:\n",
    "            crossing_times[zone, anm_n] = np.nan\n",
    "\n",
    "# Calculate crossing percentages\n",
    "crossing_percentages /= interp_all_reshaped.shape[1]\n",
    "\n",
    "# Calculate mean and SEM for each zone (excluding animals that don't cross the threshold)\n",
    "mean_crossing_times = np.nanmean(crossing_times, axis=1)\n",
    "sem_crossing_times = np.nanstd(crossing_times, axis=1) / np.sqrt(np.sum(~np.isnan(crossing_times), axis=1))\n",
    "\n",
    "print(\"Percentage of animals crossing the threshold:\")\n",
    "for zone in range(3):\n",
    "    print(f\"{labels_1[zone]}: {crossing_percentages[zone]:.2%}\")\n",
    "\n",
    "print(\"\\nNormalized time to cross threshold (mean ± SEM) for animals crossing the threshold:\")\n",
    "for zone in range(3):\n",
    "    print(f\"{labels_1[zone]}: {mean_crossing_times[zone]:.2f} ± {sem_crossing_times[zone]:.2f}\")\n",
    "\n",
    "crossing_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# After running the model and generating all the necessary data, add this code to save the variables:\n",
    "\n",
    "variables_to_save = {\n",
    "    'all_corr_runs': all_corr_runs,\n",
    "    'interp_all': interp_all,\n",
    "    'all_masks_matrix_new': all_masks_matrix_new,\n",
    "    'correlation_matrices_1': correlation_matrices_1,\n",
    "    'labels_1': labels_1,\n",
    "    'colors_1': colors_1,\n",
    "    'norm_time': norm_time,\n",
    "    'plot_reps': plot_reps\n",
    "}\n",
    "\n",
    "# Save the variables\n",
    "with open('decorrelation_analysis_data.pkl', 'wb') as f:\n",
    "    pickle.dump(variables_to_save, f)\n",
    "\n",
    "print(\"Variables saved successfully.\")\n",
    "\n",
    "# To load the variables later without running the model:\n",
    "\n",
    "with open('decorrelation_analysis_data.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)  # Changed from pickle.dump to pickle.load\n",
    "\n",
    "# Assign the loaded data to variables\n",
    "all_corr_runs = loaded_data['all_corr_runs']\n",
    "interp_all = loaded_data['interp_all']\n",
    "all_masks_matrix_new = loaded_data['all_masks_matrix_new']\n",
    "correlation_matrices_1 = loaded_data['correlation_matrices_1']\n",
    "labels_1 = loaded_data['labels_1']\n",
    "colors_1 = loaded_data['colors_1']\n",
    "norm_time = loaded_data['norm_time']\n",
    "plot_reps = loaded_data['plot_reps']\n",
    "\n",
    "print(\"Variables loaded successfully. You can now proceed with your analysis and plotting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
